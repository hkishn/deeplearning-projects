{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import random\n",
    "from PIL import Image, ImageSequence\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load training images and their corresponding images\n",
    "# TODO: Retrain the model after applying data augmentation\n",
    "def load_train_dataset(data_folder):\n",
    "    path_train_images = os.path.join(data_folder, 'train-volume.tif')\n",
    "    path_train_labels = os.path.join(data_folder, 'train-labels.tif')\n",
    "\n",
    "    images = np.array([[[np.array(page)]] for page in ImageSequence.Iterator(Image.open(path_train_images))])\n",
    "    raw_labels = np.array([np.array(page) // 255 for page in ImageSequence.Iterator(Image.open(path_train_labels))])\n",
    "    labels = np.zeros((raw_labels.reshape(-1).size, 2))\n",
    "    labels[np.arange(raw_labels.reshape(-1).size), raw_labels.reshape(-1)] = 1\n",
    "    return zip(images, labels.reshape((30, 512, 512, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(data_folder):\n",
    "    path_test_images = os.path.join(data_folder, 'test-volume.tif')\n",
    "\n",
    "    images = np.array([[[np.array(page)]] for page in ImageSequence.Iterator(Image.open(path_test_images))])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraction path (downsampling) consists of a\n",
    "### typical CNN architecture, by consecutive stacking two 3x3 convolutions (blue arrow) \n",
    "### followed by a 2x2 max pooling (red arrow) for downsampling. \n",
    "### At each downsampling step, the number of channels is doubled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2), # Adding dropout layer for regularisation\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2) # Adding dropout layer of regularisation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Each upsample block passes the input to two 3X3 CNN layers followed by a 2X2 upsampling layer. \n",
    "### Also after each block number of feature maps used by convolutional layer get half to maintain symmetry. \n",
    "### However, every time the input is also get appended by feature maps of the corresponding contraction layer. \n",
    "### This action would ensure that the features that are learned while contracting the image will be used to reconstruct it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up, self).__init__()\n",
    "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x2 = self.up_scale(x2)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class down_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down_layer, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.pool(x))\n",
    "        return x\n",
    "\n",
    "class up_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_layer, self).__init__()\n",
    "        self.up = up(in_ch, out_ch)\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        a = self.up(x1, x2)\n",
    "        x = self.conv(a)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, dimensions=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = double_conv(1, 64)\n",
    "        self.down1 = down_layer(64, 128)\n",
    "        self.down2 = down_layer(128, 256)\n",
    "        self.down3 = down_layer(256, 512)\n",
    "        self.down4 = down_layer(512, 1024)\n",
    "        self.up1 = up_layer(1024, 512)\n",
    "        self.up2 = up_layer(512, 256)\n",
    "        self.up3 = up_layer(256, 128)\n",
    "        self.up4 = up_layer(128, 64)\n",
    "        self.last_conv = nn.Conv2d(64, dimensions, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x1_up = self.up1(x4, x5)\n",
    "        x2_up = self.up2(x3, x1_up)\n",
    "        x3_up = self.up3(x2, x2_up)\n",
    "        x4_up = self.up4(x1, x3_up)\n",
    "        output = self.last_conv(x4_up)\n",
    "        return torch.sigmoid(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "model_path = 'model/unet.pt'\n",
    "saving_interval = 5\n",
    "epoch_number = 25\n",
    "from dataset import load_train_dataset, load_test_dataset\n",
    "from unet import UNet\n",
    "training_dataset = list(load_train_dataset(data_folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of weights \n",
    "### initialize  weights from a gaussian distribution with standard deviation of sqrt(N)\n",
    "### where N is the the number of input features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_normal(m):\n",
    "    # for every Conv2D  layer in a model..\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        n = m.in_channels\n",
    "        y = (1.0/np.sqrt(n))\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross entropy loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to paper use a high momentum (0.99)\n",
    "### such that a large number of the previously seen training samples determine the\n",
    "### update in the current optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:17: UserWarning: Using a target size (torch.Size([512, 512, 2])) that is different to the input size (torch.Size([1, 512, 512, 2])) is deprecated. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.41935834288597107\n",
      "Epoch: 1 \tLoss: 0.3835543096065521\n",
      "Epoch: 2 \tLoss: 0.4188568890094757\n",
      "Epoch: 3 \tLoss: 0.519564151763916\n",
      "Epoch: 4 \tLoss: 0.421855092048645\n",
      "Saving model\n",
      "Epoch: 5 \tLoss: 0.4103362262248993\n",
      "Epoch: 6 \tLoss: 0.45291823148727417\n",
      "Epoch: 7 \tLoss: 0.5653619766235352\n",
      "Epoch: 8 \tLoss: 0.5040107369422913\n",
      "Epoch: 9 \tLoss: 0.4135444462299347\n",
      "Saving model\n",
      "Epoch: 10 \tLoss: 0.47338300943374634\n",
      "Epoch: 11 \tLoss: 0.43941980600357056\n",
      "Epoch: 12 \tLoss: 0.41271787881851196\n",
      "Epoch: 13 \tLoss: 0.3778258264064789\n",
      "Epoch: 14 \tLoss: 0.41888412833213806\n",
      "Saving model\n",
      "Epoch: 15 \tLoss: 0.40619927644729614\n",
      "Epoch: 16 \tLoss: 0.40149495005607605\n",
      "Epoch: 17 \tLoss: 0.5137727856636047\n",
      "Epoch: 18 \tLoss: 0.3999673128128052\n",
      "Epoch: 19 \tLoss: 0.374215304851532\n",
      "Saving model\n",
      "Epoch: 20 \tLoss: 0.4518355429172516\n",
      "Epoch: 21 \tLoss: 0.41597214341163635\n",
      "Epoch: 22 \tLoss: 0.38572871685028076\n",
      "Epoch: 23 \tLoss: 0.3439171016216278\n",
      "Epoch: 24 \tLoss: 0.3778289556503296\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model = UNet(dimensions=2)\n",
    "    model.apply(weights_init_normal)\n",
    "    if os.path.isfile(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    #optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
    "    training_dataset = list(load_train_dataset(data_folder))\n",
    "    for epoch in range(epoch_number):\n",
    "        #running_loss = 0\n",
    "        i = random.randint(0, len(training_dataset) - 1)\n",
    "            \n",
    "        (input, label) = training_dataset[i]\n",
    "        optimizer.zero_grad()\n",
    "        target = torch.from_numpy(label).float()\n",
    "        output = model(torch.from_numpy(input.astype(np.float32))).permute(0, 2, 3, 1)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        step_loss = loss.item()\n",
    "        print(f'Epoch: {epoch} \\tLoss: {step_loss}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()                    \n",
    "\n",
    "        if (epoch + 1) % saving_interval == 0:\n",
    "            print('Saving model')\n",
    "\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that performance is not improving much after 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data'\n",
    "model_path = 'model/unet.pt'\n",
    "\n",
    "def predict():\n",
    "    model = UNet()\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint) \n",
    "    image_count = 1\n",
    "    for input in load_test_dataset(data_folder):\n",
    "        output = model(torch.from_numpy(input.astype(np.float32))).permute(0, 2, 3, 1).detach().numpy()\n",
    "        input_array = input.reshape((512, 512))\n",
    "        output_array = output.argmax(3).reshape((512, 512)) * 255\n",
    "        input_img = Image.fromarray(input_array)\n",
    "        output_img = Image.fromarray(output_array.astype(dtype=np.uint16)).convert('L')\n",
    "        input_img.save('output/input_image'+str(image_count)+\".png\")\n",
    "        output_img.save('output/output_image'+str(image_count)+\".png\")\n",
    "        image_count = image_count +1\n",
    "        print(image_count)\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
